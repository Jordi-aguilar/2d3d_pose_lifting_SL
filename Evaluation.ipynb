{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the imports from other files in the project\n",
    "from Model.DepthLSTM import DepthLSTM\n",
    "from Train.hyperparameters import *\n",
    "from Train.train_epoch_J import train_epoch_J\n",
    "from Train.test_epoch_J import test_epoch_J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_videos = './Data/Preprocessed_J/'\n",
    "list_videos = os.listdir(path_videos)\n",
    "videos_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in list_videos:\n",
    "    path_video = path_videos + video\n",
    "    videos_data.append(np.load(path_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_data[15].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define test set and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_idx = [0, 4, 9, 12, 21]\n",
    "trainset_idx = list(set(range(24)) - set(testset_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videos = [videos_data[i] for i in trainset_idx]\n",
    "test_videos = [videos_data[i] for i in testset_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinVideos(videos_data):\n",
    "    span_videos = []\n",
    "    for video in videos_data:\n",
    "        span_vid = np.ones(len(video))\n",
    "        span_vid[0] = 0\n",
    "        span_videos.append(span_vid)\n",
    "    span_videos = np.concatenate(span_videos)\n",
    "    videos_data = np.concatenate(videos_data)\n",
    "    return videos_data, span_videos\n",
    "\n",
    "\n",
    "def reshapeBatches(vid_data, BATCH_SIZE, SEQ_LEN):\n",
    "    num_batches = vid_data.shape[0] // (BATCH_SIZE*SEQ_LEN)\n",
    "    cut_vid = vid_data[:num_batches*BATCH_SIZE*SEQ_LEN,]\n",
    "    reshaped_vid = cut_vid.reshape(BATCH_SIZE, num_batches, SEQ_LEN, -1)\n",
    "    reordered_vid = np.transpose(reshaped_vid, (1, 2, 0, 3))\n",
    "    \n",
    "    return reordered_vid\n",
    "\n",
    "\n",
    "def splitInputOutput(vid_data):\n",
    "    ground_idx = list(range(2,201,3))\n",
    "    input_idx = list(set(range(201)) - set(ground_idx))\n",
    "    \n",
    "    input_vid = vid_data[:,:,:,input_idx]\n",
    "    output_vid = vid_data[:,:,:,ground_idx]\n",
    "    \n",
    "    return input_vid, output_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stateful_dataset(videos, shuffle = True):\n",
    "    if shuffle:\n",
    "        random.shuffle(videos)\n",
    "        \n",
    "    videos_set, span_videos = joinVideos(videos)\n",
    "    \n",
    "    dataset = reshapeBatches(videos_set, BATCH_SIZE, SEQ_LEN)\n",
    "    span_videos = reshapeBatches(span_videos, BATCH_SIZE, SEQ_LEN)\n",
    "    \n",
    "    dataset, grounddataset = splitInputOutput(dataset)\n",
    "    \n",
    "    dataset = dataset.astype(np.float32)\n",
    "    grounddataset = grounddataset.astype(np.float32)\n",
    "    \n",
    "    return dataset, grounddataset, span_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeThresholds(input_data, gt, reference):\n",
    "    new_shape = input_data.shape[:-1]\n",
    "    new_shape = list(new_shape) + [1]\n",
    "    thresholds = np.zeros(new_shape)\n",
    "    for i in range(input_data.shape[0]):\n",
    "        for j in range(input_data.shape[1]):\n",
    "            for k in range(input_data.shape[2]):\n",
    "                a_x = input_data[i,j,k,reference[0]*2]\n",
    "                a_y = input_data[i,j,k,reference[0]*2 + 1]\n",
    "                a_z = gt[i,j,k,reference[0]]\n",
    "                b_x = input_data[i,j,k,reference[1]*2]\n",
    "                b_y = input_data[i,j,k,reference[1]*2 + 1]\n",
    "                b_z = gt[i,j,k,reference[1]]\n",
    "                \n",
    "                a = np.array([a_x-b_x, a_y-b_y, a_z-b_z])\n",
    "                dist = np.linalg.norm(a)\n",
    "                \n",
    "                thresholds[i,j,k,:] = dist\n",
    "                \n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, input_data, gt, span, reference, alpha = 0.1, hands = False):\n",
    "    loss_function = nn.L1Loss()\n",
    "    test_epoch_loss, predY = test_epoch_J(model, input_data, gt, span, loss_function)\n",
    "    predY = np.squeeze(np.array(predY))\n",
    "    \n",
    "    thresholds = computeThresholds(input_data, gt, reference)\n",
    "    classification = abs(predY - gt) <= thresholds*alpha\n",
    "    \n",
    "    classification_hands = classification[:,:,:,25:]\n",
    "    \n",
    "    #print(classification_hands.shape)\n",
    "    \n",
    "    # print(classification.sum(), classification.sum()/classification.size)\n",
    "    \n",
    "    #computePCK(input_data, gt, output, , alpha)\n",
    "    \n",
    "    if hands:\n",
    "        return classification_hands.sum()/classification_hands.size\n",
    "    else:\n",
    "        return classification.sum()/classification.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, groundtrainset, span_videos_train = create_stateful_dataset(train_videos, shuffle = False)\n",
    "testset, groundtestset, span_videos_test = create_stateful_dataset(test_videos, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take into account only the hands\n",
    "hands_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = \"./Output/J_300.pt\"\n",
    "model = torch.load(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference is the two joints of the bone that we take as reference.\n",
    "reference = (0, 2)\n",
    "\n",
    "t = evaluate_model(model, testset, groundtestset, span_videos_test, reference, hands = hands_flag)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with different alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_v = np.arange(0.01, 0.5, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean = []\n",
    "for alpha in alpha_v:\n",
    "    acc_clean.append(evaluate_model(model, testset, groundtestset, span_videos_test, reference, alpha=alpha, hands = hands_flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_2 = \"./Output/M_300.pt\"\n",
    "model_2 = torch.load(path_model_2)\n",
    "\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = evaluate_model(model_2, testset, groundtestset, span_videos_test, reference, hands = hands_flag)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_raw = []\n",
    "for alpha in alpha_v:\n",
    "    acc_raw.append(evaluate_model(model_2, testset, groundtestset, span_videos_test, reference, alpha=alpha, hands = hands_flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alpha_v, acc_clean, label = 'preprocessed')\n",
    "plt.plot(alpha_v, acc_raw, label = 'raw')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('PCK')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_loss_file(path):\n",
    "    \n",
    "    with open(\"./Output/\" + path, 'r') as f:\n",
    "        loss = f.readlines()\n",
    "        loss = [float(l) for l in loss]\n",
    "        \n",
    "    return loss\n",
    "\n",
    "def get_losses(name):\n",
    "    train_loss_path = name + \"_train_loss.txt\"\n",
    "    test_loss_path = name + \"_test_loss.txt\"\n",
    "    \n",
    "    train_loss = read_loss_file(train_loss_path)\n",
    "    test_loss = read_loss_file(test_loss_path)\n",
    "    \n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_m = \"M\"\n",
    "\n",
    "train_loss_m, test_loss_m = get_losses(name_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_m, label = 'train')\n",
    "plt.plot(test_loss_m, label = 'test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_j = \"J\"\n",
    "\n",
    "train_loss_j, test_loss_j = get_losses(name_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_j, label = 'train')\n",
    "plt.plot(test_loss_j, label = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
